{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header-imports",
      "metadata": {},
      "source": [
        "# Temperature Prediction Experiments with Multiple Models\n",
        "\n",
        "This notebook compares R2C2, Ridge, and Random Forest models for indoor temperature prediction across different noise levels."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-imports-cell",
      "metadata": {},
      "source": [
        "## Imports and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "from scipy.linalg import expm, inv\n",
        "from scipy.stats import norm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-load-data",
      "metadata": {},
      "source": [
        "## Load R2C2 Optimization Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-r2c2-results",
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_optimization_results_from_csv(sensor_counts):\n",
        "    \"\"\"\n",
        "    Reads R2C2 optimization results from CSV files.\n",
        "\n",
        "    Parameters:\n",
        "    - sensor_counts: List of sensor counts to identify which CSV files to read\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary with structure [sensor_count][house_id] containing optimization outcomes\n",
        "    \"\"\"\n",
        "    optimization_results = {}\n",
        "    for sensor_count in sensor_counts:\n",
        "        file_name = f\"/Users/ozanbaris/Documents/GitHub/TS-foundation-model/R2C2_models/decent_R2C2_optimization_results_sensor_{sensor_count}.csv\"\n",
        "        if os.path.exists(file_name):\n",
        "            df = pd.read_csv(file_name)\n",
        "            houses = {}\n",
        "            for _, row in df.iterrows():\n",
        "                house_id = row['House ID']\n",
        "                results = {\n",
        "                    'rmse_train': row['RMSE Train'],\n",
        "                    'rmse_test': row['RMSE Test'],\n",
        "                    'optimal_params': {\n",
        "                        'Ri': list(map(float, row['Ri_values'].split(', '))),\n",
        "                        'Re': list(map(float, row['Re_values'].split(', '))),\n",
        "                        'Ci': list(map(float, row['Ci_values'].split(', '))),\n",
        "                        'Ce': list(map(float, row['Ce_values'].split(', '))),\n",
        "                        'Ai': list(map(float, row['Ai_values'].split(', '))),\n",
        "                        'Ae': list(map(float, row['Ae_values'].split(', '))),\n",
        "                        'roxP_hvac': list(map(float, row['roxP_hvac'].split(', ')))\n",
        "                    }\n",
        "                }\n",
        "                houses[house_id] = results\n",
        "            \n",
        "            optimization_results[sensor_count] = houses\n",
        "        else:\n",
        "            print(f\"File '{file_name}' not found.\")\n",
        "    \n",
        "    return optimization_results\n",
        "\n",
        "\n",
        "sensor_counts = [1, 2, 3, 4, 5] \n",
        "optimization_results_R2C2_decent = read_optimization_results_from_csv(sensor_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-models",
      "metadata": {},
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r2c2-model",
      "metadata": {},
      "outputs": [],
      "source": [
        "class R2C2Model:\n",
        "    \"\"\"\n",
        "    R2C2 (2 Resistances, 2 Capacitances) thermal model for building temperature prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, Ri, Re, Ci, Ce, Ai, Ae, roxP_hvac):\n",
        "        self.Ri = Ri\n",
        "        self.Re = Re\n",
        "        self.Ci = Ci\n",
        "        self.Ce = Ce\n",
        "        self.Ai = Ai\n",
        "        self.Ae = Ae\n",
        "        self.roxP_hvac = roxP_hvac\n",
        "        self.N_states = 2\n",
        "        self.update_matrices()\n",
        "\n",
        "    def update_matrices(self):\n",
        "        \"\"\"Update continuous-time state-space matrices.\"\"\"\n",
        "        self.Ac = np.array([[-1/(self.Ci*self.Ri), 1/(self.Ci*self.Ri)],\n",
        "                            [1/(self.Ce*self.Ri), -1/(self.Ce*self.Ri) - 1/(self.Ce*self.Re)]])\n",
        "        self.Bc = np.array([[0, -self.roxP_hvac / self.Ci, self.Ai / self.Ci],\n",
        "                            [1/(self.Ce*self.Re), 0, self.Ae/self.Ce]])\n",
        "        self.Cc = np.array([[1, 0]])\n",
        "\n",
        "    def discretize(self, dt):\n",
        "        \"\"\"Discretize continuous-time model.\"\"\"\n",
        "        n = self.N_states\n",
        "        F = expm(self.Ac * dt)\n",
        "        G = np.dot(inv(self.Ac), np.dot(F - np.eye(n), self.Bc))\n",
        "        H = self.Cc\n",
        "        return F, G\n",
        "    \n",
        "    def predict_onestep(self, T, Te, T_ext, u, ghi, dt):\n",
        "        \"\"\"\n",
        "        One-step temperature prediction using vectorized operations.\n",
        "        \n",
        "        Parameters:\n",
        "        - T: Indoor temperatures (K)\n",
        "        - Te: Envelope temperatures (K)\n",
        "        - T_ext: External temperatures (K)\n",
        "        - u: HVAC duty cycle (fraction of time on)\n",
        "        - ghi: Solar radiation (W/m²)\n",
        "        - dt: Time step (seconds)\n",
        "        \n",
        "        Returns:\n",
        "        - Predicted indoor temperatures (K)\n",
        "        \"\"\"\n",
        "        F, G = self.discretize(dt)\n",
        "        \n",
        "        # Stack T and Te vertically, then transpose to get a 2xN matrix where N is the number of samples\n",
        "        state_matrix = np.vstack((T, Te)).T  # Each row is [T, Te] for a timestep\n",
        "        \n",
        "        # Similarly, stack T_ext, u, and ghi vertically and transpose\n",
        "        input_matrix = np.vstack((T_ext, u, ghi)).T  # Each row is [T_ext, u, ghi] for a timestep\n",
        "        \n",
        "        # Perform the matrix multiplication in a batch\n",
        "        predictions = (F @ state_matrix.T) + (G @ input_matrix.T)\n",
        "        \n",
        "        # Transpose the result back so each row corresponds to a timestep\n",
        "        predictions = predictions.T\n",
        "        \n",
        "        # And only return the first column, which represents T\n",
        "        return predictions[:, 0]\n",
        "    \n",
        "    def predict_two(self, T, Te, T_ext, u, ghi, dt):\n",
        "        \"\"\"Predict both indoor and envelope temperatures.\"\"\"\n",
        "        F, G = self.discretize(dt)\n",
        "        state_matrix = np.vstack((T, Te)).T\n",
        "        input_matrix = np.vstack((T_ext, u, ghi)).T\n",
        "        predictions = (F @ state_matrix.T) + (G @ input_matrix.T)\n",
        "        predictions = predictions.T\n",
        "        return predictions[:, 0], predictions[:, 1]\n",
        "    \n",
        "    def autoregressive_predict(self, T_init, Te_init, T_ext_seq, u_seq, ghi_seq, dt, pred_hrz=64):\n",
        "        \"\"\"\n",
        "        Autoregressive temperature predictions.\n",
        "\n",
        "        Parameters:\n",
        "        - T_init: Initial indoor temperature (K)\n",
        "        - Te_init: Initial envelope temperature (K)\n",
        "        - T_ext_seq: Sequence of external temperatures (K)\n",
        "        - u_seq: Sequence of HVAC duty cycles\n",
        "        - ghi_seq: Sequence of solar radiation values (W/m²)\n",
        "        - dt: Time step (seconds)\n",
        "        - pred_hrz: Prediction horizon (number of steps)\n",
        "\n",
        "        Returns:\n",
        "        - Array of predicted indoor temperatures (°F)\n",
        "        \"\"\"\n",
        "        T = np.zeros(pred_hrz)\n",
        "        Te = Te_init\n",
        "        preds = []\n",
        "        \n",
        "        for t in range(0, pred_hrz):\n",
        "            if t == 0:\n",
        "                T_pred = self.predict_onestep(\n",
        "                    T_init, Te_init,\n",
        "                    T_ext_seq[0], u_seq[0], ghi_seq[0], dt\n",
        "                )\n",
        "            else:\n",
        "                T_pred, _ = self.predict_two(\n",
        "                    T_prev, Te,\n",
        "                    T_ext_seq[t], u_seq[t], ghi_seq[t], dt\n",
        "                )\n",
        "            preds.append(T_pred)\n",
        "            T_prev = T_pred\n",
        "            Te = (T_pred + T_ext_seq[t]) / 2\n",
        "\n",
        "        # Convert Kelvin to Fahrenheit\n",
        "        preds = (np.array(preds) - 273.15) * 9/5 + 32\n",
        "        \n",
        "        return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-data-utils",
      "metadata": {},
      "source": [
        "## Data Loading and Processing Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "data-utils",
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_csvs_to_dfs(main_output_directory):\n",
        "    \"\"\"\n",
        "    Reads all house CSV files from subdirectories.\n",
        "    \n",
        "    Parameters:\n",
        "    - main_output_directory: Root directory containing subdirectories with house data\n",
        "    \n",
        "    Returns:\n",
        "    - Dictionary with structure [house_group][house_id] containing DataFrames\n",
        "    \"\"\"\n",
        "    all_houses_dict = {}\n",
        "    \n",
        "    for subdirectory in os.listdir(main_output_directory):\n",
        "        sub_output_directory = os.path.join(main_output_directory, subdirectory)\n",
        "        \n",
        "        if not os.path.isdir(sub_output_directory):\n",
        "            continue\n",
        "        \n",
        "        house_group = int(subdirectory.split(\"_\")[-1])\n",
        "        \n",
        "        if house_group not in all_houses_dict:\n",
        "            all_houses_dict[house_group] = {}\n",
        "        \n",
        "        for filename in os.listdir(sub_output_directory):\n",
        "            if filename.endswith(\".csv\"):\n",
        "                file_path = os.path.join(sub_output_directory, filename)\n",
        "                house_id = filename.split(\"_\")[-1].replace(\".csv\", \"\")\n",
        "                df = pd.read_csv(file_path)\n",
        "                all_houses_dict[house_group][house_id] = df\n",
        "                \n",
        "    return all_houses_dict\n",
        "\n",
        "\n",
        "def process_house_data(df):\n",
        "    \"\"\"\n",
        "    Processes a single house DataFrame: normalizes duty cycle, renames columns, \n",
        "    converts temperatures to Kelvin, and handles missing values.\n",
        "    \"\"\"\n",
        "    df['duty_cycle'] = df['CoolingRunTime'] / 3600\n",
        "    df.rename(columns={'Outdoor_Temperature': 'Text'}, inplace=True)\n",
        "    \n",
        "    sensor_rename_map = {\n",
        "        'Thermostat_Temperature': 'T01_TEMP',\n",
        "        'RemoteSensor1_Temperature': 'T02_TEMP',\n",
        "        'RemoteSensor2_Temperature': 'T03_TEMP',\n",
        "        'RemoteSensor3_Temperature': 'T04_TEMP',\n",
        "        'RemoteSensor4_Temperature': 'T05_TEMP',\n",
        "        'RemoteSensor5_Temperature': 'T06_TEMP',\n",
        "    }\n",
        "    df.rename(columns=sensor_rename_map, inplace=True)\n",
        "\n",
        "    temp_columns = [f\"T0{i}_TEMP\" for i in range(1, 7)] + ['Text']\n",
        "    for col in temp_columns:\n",
        "        df[col] = (df[col] - 32) * 5/9 + 273.15\n",
        "\n",
        "    columns_to_keep = ['time', 'GHI', 'duty_cycle'] + temp_columns\n",
        "    df = df[columns_to_keep]\n",
        "    df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_experiment_data(dataset_name, optimization_results):\n",
        "    \"\"\"\n",
        "    Loads and prepares all experiment data including house rankings and flattened results.\n",
        "    \n",
        "    Parameters:\n",
        "    - dataset_name: Name of the dataset directory\n",
        "    - optimization_results: R2C2 optimization results dictionary\n",
        "    \n",
        "    Returns:\n",
        "    - Tuple of (new_house_data, flattened_results, flattened_data)\n",
        "    \"\"\"\n",
        "    main_output_directory = f\"/Users/ozanbaris/Documents/GitHub/TS-foundation-model/{dataset_name}\"\n",
        "    all_houses_reduced = read_csvs_to_dfs(main_output_directory)\n",
        "    \n",
        "    # Flatten and sort the house data\n",
        "    new_house_data = {}\n",
        "    total = 0\n",
        "    house_data = OrderedDict(sorted(all_houses_reduced.items()))\n",
        "    \n",
        "    for house_group in house_data:\n",
        "        sorted_dict = OrderedDict(sorted(house_data[house_group].items()))\n",
        "        for house_id in sorted_dict:\n",
        "            total += 1\n",
        "            new_house_data[house_id] = total\n",
        "    \n",
        "    # Process houses\n",
        "    processed_houses_reduced = {}\n",
        "    for sensor_count, houses in all_houses_reduced.items():\n",
        "        processed_houses = {}\n",
        "        for house_id, df in houses.items():\n",
        "            if 'GHI' not in df.columns:\n",
        "                print(f\"Skipping house {house_id} due to missing 'GHI' column.\")\n",
        "                continue\n",
        "            processed_houses[house_id] = process_house_data(df.copy())\n",
        "        processed_houses_reduced[sensor_count] = processed_houses\n",
        "    \n",
        "    # Flatten optimization results\n",
        "    flattened_results = {}\n",
        "    for sensor_count, houses in optimization_results.items():\n",
        "        for house_id, result in houses.items():\n",
        "            flattened_results[house_id] = result\n",
        "    \n",
        "    # Flatten processed data\n",
        "    flattened_data = {}\n",
        "    for sensor_count, houses in processed_houses_reduced.items():\n",
        "        for house_id, df in houses.items():\n",
        "            flattened_data[house_id] = df\n",
        "    \n",
        "    return new_house_data, flattened_results, flattened_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-metrics",
      "metadata": {},
      "source": [
        "## Metrics and Results Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "metrics-utils",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_normalized_rmse(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate normalized RMSE.\n",
        "    \n",
        "    Returns:\n",
        "    - RMSE normalized by the range of ground truth values\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    \n",
        "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "    range_of_data = np.max(y_true) - np.min(y_true)\n",
        "    normalized_rmse = rmse / (range_of_data + 1e-20)\n",
        "    \n",
        "    return normalized_rmse\n",
        "\n",
        "\n",
        "def calculate_metrics(gt, forecast):\n",
        "    \"\"\"\n",
        "    Calculate MSE, RMSE, and normalized RMSE.\n",
        "    \n",
        "    Returns:\n",
        "    - Tuple of (mse, rmse, normalized_rmse)\n",
        "    \"\"\"\n",
        "    gt = np.float64(gt)\n",
        "    if np.sum(np.isnan(forecast)) >= 1 or np.sum(np.isnan(gt)) >= 1:\n",
        "        print('NaN detected...')\n",
        "    \n",
        "    mse = np.mean((gt - forecast) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    normalized_rmse = calc_normalized_rmse(gt, forecast)\n",
        "    return mse, rmse, normalized_rmse\n",
        "\n",
        "\n",
        "def save_results_for_model(model_name, ground_truth, timestamp_forecast, forecast, \n",
        "                           duration, pred_hrz, mode, occupancy, batch_id, directory):\n",
        "    \"\"\"\n",
        "    Save model predictions and metrics to CSV file.\n",
        "    \"\"\"\n",
        "    mse, rmse, normalized_rmse = calculate_metrics(ground_truth, forecast)\n",
        "\n",
        "    result = {\n",
        "        'batch_id': batch_id,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse, \n",
        "        'Norm_RMSE': normalized_rmse, \n",
        "        'GroundTruth': ground_truth.tolist(),\n",
        "        'Timestamp_forecast': timestamp_forecast.tolist(),\n",
        "        'Forecast': forecast.tolist(),\n",
        "        'Duration': duration,\n",
        "        'PredictionHorizon': pred_hrz,\n",
        "        'Mode': mode,\n",
        "        'Occupancy': occupancy,\n",
        "        'Model': model_name\n",
        "    }\n",
        "\n",
        "    file_path = f\"{directory}/results_{mode}_{occupancy}/{duration}_{pred_hrz}/{model_name}.csv\"\n",
        "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        df = pd.DataFrame(columns=['batch_id', 'MSE', 'RMSE', 'Norm_RMSE', 'Mode', \n",
        "                                   'Occupancy', 'Duration', 'PredictionHorizon', 'Data', \n",
        "                                   'Timestamp_data', 'GroundTruth', 'Timestamp_forecast', \n",
        "                                   'Forecast', 'Model'])\n",
        "\n",
        "    df = pd.concat([df, pd.DataFrame([result])], ignore_index=True)\n",
        "    df.to_csv(file_path, index=False)\n",
        "\n",
        "\n",
        "def compute_metrics(ground_truth, forecast):\n",
        "    \"\"\"\n",
        "    Compute RMSE metrics for different prediction horizons.\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary with RMSE for all predictions, 1st, 6th, and 24th steps\n",
        "    \"\"\"\n",
        "    metrics = {\n",
        "        'RMSE_all': np.sqrt(np.mean((ground_truth - forecast) ** 2)),\n",
        "        'RMSE_1st': np.sqrt(np.mean((ground_truth[:, 0] - forecast[:, 0]) ** 2)) if forecast.shape[1] > 0 else None,\n",
        "        'RMSE_6th': np.sqrt(np.mean((ground_truth[:, 5] - forecast[:, 5]) ** 2)) if forecast.shape[1] > 5 else None,\n",
        "        'RMSE_24th': np.sqrt(np.mean((ground_truth[:, 23] - forecast[:, 23]) ** 2)) if forecast.shape[1] > 23 else None\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def extract_valid_occupancies(flattened_data, flattened_results, new_house_data):\n",
        "    \"\"\"\n",
        "    Extract valid occupancy ranks for houses with complete data.\n",
        "    \"\"\"\n",
        "    valid_occupancies = []\n",
        "    for house_id, house_data in flattened_data.items():\n",
        "        if house_id in flattened_results:\n",
        "            rank = new_house_data[house_id]\n",
        "            valid_occupancies.append(rank)\n",
        "        else:\n",
        "            print(f\"Skipping house ID: {house_id} due to missing optimization results.\")\n",
        "    return valid_occupancies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-prediction",
      "metadata": {},
      "source": [
        "## Autoregressive Prediction Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prediction-functions",
      "metadata": {},
      "outputs": [],
      "source": [
        "def autoregressive_predict_ridge(ridge_model, test_df, pred_hrz=24):\n",
        "    \"\"\"\n",
        "    Autoregressive forecast for Ridge regression with covariates.\n",
        "    Predicts T(t+1) from [Text(t), duty_cycle(t), GHI(t), T01_TEMP(t)].\n",
        "    \n",
        "    Returns:\n",
        "    - Temperature predictions in Fahrenheit\n",
        "    \"\"\"\n",
        "    preds_K = []\n",
        "    T_init = test_df['T01_TEMP'].iloc[0]\n",
        "    T_prev = T_init\n",
        "  \n",
        "    for t in range(0, pred_hrz):\n",
        "        features = {\n",
        "            'Text': test_df['Text'].iloc[t],\n",
        "            'duty_cycle': test_df['duty_cycle'].iloc[t],\n",
        "            'GHI': test_df['GHI'].iloc[t],\n",
        "            'T01_TEMP': T_prev\n",
        "        }\n",
        "        X = pd.DataFrame([features])\n",
        "        T_next = ridge_model.predict(X)[0]\n",
        "        preds_K.append(T_next)\n",
        "        T_prev = T_next\n",
        "\n",
        "    T_pred_F = (np.array(preds_K) - 273.15) * 9/5 + 32\n",
        "    return T_pred_F\n",
        "\n",
        "\n",
        "def autoregressive_predict_rf(rf_model, test_df, pred_hrz=24):\n",
        "    \"\"\"\n",
        "    Autoregressive forecast for Random Forest with covariates.\n",
        "    Predicts T(t+1) from [Text(t), duty_cycle(t), GHI(t), T01_TEMP(t)].\n",
        "    \n",
        "    Returns:\n",
        "    - Temperature predictions in Fahrenheit\n",
        "    \"\"\"\n",
        "    preds_K = []\n",
        "    T_init = test_df['T01_TEMP'].iloc[0]\n",
        "    T_prev = T_init\n",
        "    \n",
        "    for t in range(0, pred_hrz):\n",
        "        features = {\n",
        "            'Text': test_df['Text'].iloc[t],\n",
        "            'duty_cycle': test_df['duty_cycle'].iloc[t],\n",
        "            'GHI': test_df['GHI'].iloc[t],\n",
        "            'T01_TEMP': T_prev\n",
        "        }\n",
        "        X = pd.DataFrame([features])\n",
        "        T_next = rf_model.predict(X)[0]\n",
        "        preds_K.append(T_next)\n",
        "        T_prev = T_next\n",
        "\n",
        "    T_pred_F = (np.array(preds_K) - 273.15) * 9/5 + 32\n",
        "    return T_pred_F\n",
        "\n",
        "\n",
        "def autoregressive_predict_ridge_univariate(ridge_model, test_df, pred_hrz=24):\n",
        "    \"\"\"\n",
        "    Univariate autoregressive forecast for Ridge.\n",
        "    Predicts T(t+1) using only T(t).\n",
        "    \n",
        "    Note: Model must have been trained using only 'T01_TEMP' as feature.\n",
        "    \n",
        "    Returns:\n",
        "    - Temperature predictions in Fahrenheit\n",
        "    \"\"\"\n",
        "    preds_K = []\n",
        "    T_prev = test_df['T01_TEMP'].iloc[0]\n",
        "  \n",
        "    for _ in range(pred_hrz):\n",
        "        X = pd.DataFrame({'T01_TEMP': [T_prev]})\n",
        "        T_next = ridge_model.predict(X)[0]\n",
        "        preds_K.append(T_next)\n",
        "        T_prev = T_next\n",
        "\n",
        "    T_pred_F = (np.array(preds_K) - 273.15) * 9/5 + 32\n",
        "    return T_pred_F\n",
        "\n",
        "\n",
        "def autoregressive_predict_rf_univariate(rf_model, test_df, pred_hrz=24):\n",
        "    \"\"\"\n",
        "    Univariate autoregressive forecast for Random Forest.\n",
        "    Predicts T(t+1) using only T(t).\n",
        "    \n",
        "    Note: Model must have been trained using only 'T01_TEMP' as feature.\n",
        "    \n",
        "    Returns:\n",
        "    - Temperature predictions in Fahrenheit\n",
        "    \"\"\"\n",
        "    preds_K = []\n",
        "    T_prev = test_df['T01_TEMP'].iloc[0]\n",
        "\n",
        "    for _ in range(pred_hrz):\n",
        "        X = pd.DataFrame({'T01_TEMP': [T_prev]})\n",
        "        T_next = rf_model.predict(X)[0]\n",
        "        preds_K.append(T_next)\n",
        "        T_prev = T_next\n",
        "\n",
        "    T_pred_F = (np.array(preds_K) - 273.15) * 9/5 + 32\n",
        "    return T_pred_F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-training",
      "metadata": {},
      "source": [
        "## Training and Testing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "training-function",
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_and_testing_baselines(all_houses_reduced, optimization_results_R2C2_decent, \n",
        "                                   processed_houses_reduced, pred_hrz, duration, noise, \n",
        "                                   mode, batch_id):\n",
        "    \"\"\"\n",
        "    Train and test R2C2, Ridge, and Random Forest models (both multivariate and univariate).\n",
        "    \"\"\"\n",
        "    # Flatten and sort the house data\n",
        "    new_house_data = {}\n",
        "    total = 0\n",
        "    house_data = OrderedDict(sorted(all_houses_reduced.items()))\n",
        "\n",
        "    for house_group in house_data:\n",
        "        sorted_dict = OrderedDict(sorted(house_data[house_group].items()))\n",
        "        for house_id in sorted_dict:\n",
        "            total += 1\n",
        "            new_house_data[house_id] = total\n",
        "            \n",
        "    # Reorganize the dictionary to remove the sensor_count key\n",
        "    flattened_results = {}\n",
        "    for sensor_count, houses in optimization_results_R2C2_decent.items():\n",
        "        for house_id, result in houses.items():\n",
        "            flattened_results[house_id] = result\n",
        "\n",
        "    flattened_data = {}\n",
        "    for sensor_count, houses in processed_houses_reduced.items():\n",
        "        for house_id, df in houses.items():\n",
        "            flattened_data[house_id] = df\n",
        "\n",
        "    # Process each house\n",
        "    for house_id, house_data_df in flattened_data.items():\n",
        "        rank = new_house_data[house_id]\n",
        "        print(f\"\\nHouse ID {house_id} with rank {rank}\")\n",
        "\n",
        "        if house_id not in flattened_results:\n",
        "            print(f\"Skipping house {house_id} (no R2C2 results).\")\n",
        "            continue\n",
        "\n",
        "        # Extract R2C2 parameters and initialize model\n",
        "        results = flattened_results[house_id]\n",
        "        optimal_params = results['optimal_params']\n",
        "\n",
        "        Ri = optimal_params['Ri'][0]\n",
        "        Re = optimal_params['Re'][0]\n",
        "        Ci = optimal_params['Ci'][0]\n",
        "        Ce = optimal_params['Ce'][0]\n",
        "        Ai = optimal_params['Ai'][0]\n",
        "        Ae = optimal_params['Ae'][0]\n",
        "        roxP_hvac = optimal_params['roxP_hvac'][0]\n",
        "\n",
        "        r2c2_model = R2C2Model(Ri, Re, Ci, Ce, Ai, Ae, roxP_hvac)\n",
        "\n",
        "        # Train/test split\n",
        "        test_size = 0.125\n",
        "        num_test_samples = int(len(house_data_df) * test_size)\n",
        "        split_index = len(house_data_df) - num_test_samples\n",
        "\n",
        "        train_df = house_data_df.iloc[224:split_index].copy()\n",
        "        test_df = house_data_df.iloc[split_index:].copy()\n",
        "        print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
        "        \n",
        "        # R2C2 Autoregressive predictions\n",
        "        T_init = test_df['T01_TEMP'].iloc[0]\n",
        "        T_ext_init = test_df['Text'].iloc[0]\n",
        "        Te_init = (T_init + T_ext_init) / 2\n",
        "\n",
        "        T_ext_seq = test_df['Text'].iloc[:pred_hrz].values\n",
        "        u_seq = test_df['duty_cycle'].iloc[:pred_hrz].values\n",
        "        ghi_seq = test_df['GHI'].iloc[:pred_hrz].values\n",
        "\n",
        "        predictions_r2c2 = r2c2_model.autoregressive_predict(\n",
        "            T_init, Te_init, T_ext_seq, u_seq, ghi_seq, dt=3600, pred_hrz=pred_hrz\n",
        "        )\n",
        "\n",
        "        # Ground truth in Fahrenheit\n",
        "        ground_truth_K = test_df['T01_TEMP'].iloc[1:pred_hrz+1].values\n",
        "        ground_truth_F = (ground_truth_K - 273.15) * 9/5 + 32\n",
        "\n",
        "        rmse_r2c2 = np.sqrt(mean_squared_error(ground_truth_F, predictions_r2c2))\n",
        "        print(f\"[R2C2] RMSE = {rmse_r2c2:.2f} F\")\n",
        "\n",
        "        model_name = \"R2C2\"\n",
        "        directory = f'/Users/ozanbaris/Documents/GitHub/TS-foundation-model/Aug18_ecobee_results_{noise}/{model_name}_new_ecobee_cov_{noise}_csv' \n",
        "        save_results_for_model(\n",
        "            model_name=model_name,\n",
        "            ground_truth=ground_truth_F,\n",
        "            timestamp_forecast=test_df.index[:pred_hrz],\n",
        "            forecast=predictions_r2c2,\n",
        "            duration=duration,\n",
        "            pred_hrz=pred_hrz,\n",
        "            mode=mode,\n",
        "            occupancy=rank,\n",
        "            batch_id=batch_id,\n",
        "            directory=directory\n",
        "        )\n",
        "\n",
        "        # Prepare training data for Ridge & RF (multivariate)\n",
        "        X_train = train_df[['Text', 'duty_cycle', 'GHI', 'T01_TEMP']][:-1]\n",
        "        y_train = train_df['T01_TEMP'][1:]\n",
        "        print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "        \n",
        "        # Fit and test Ridge (multivariate)\n",
        "        ridge_model = Ridge()\n",
        "        ridge_model.fit(X_train, y_train)\n",
        "\n",
        "        predictions_ridge = autoregressive_predict_ridge(\n",
        "            ridge_model, test_df, pred_hrz=pred_hrz\n",
        "        )\n",
        "        rmse_ridge = np.sqrt(mean_squared_error(ground_truth_F, predictions_ridge))\n",
        "        print(f\"[Ridge] RMSE = {rmse_ridge:.2f} F\")\n",
        "        \n",
        "        model_name = \"Ridge\"\n",
        "        directory = f'/Users/ozanbaris/Documents/GitHub/TS-foundation-model/Aug18_ecobee_results_{noise}/{model_name}_new_ecobee_cov_{noise}_csv' \n",
        "        save_results_for_model(\n",
        "            model_name=model_name,\n",
        "            ground_truth=ground_truth_F,\n",
        "            timestamp_forecast=test_df.index[:pred_hrz],\n",
        "            forecast=predictions_ridge,\n",
        "            duration=duration,\n",
        "            pred_hrz=pred_hrz,\n",
        "            mode=mode,\n",
        "            occupancy=rank,\n",
        "            batch_id=batch_id,\n",
        "            directory=directory\n",
        "        )\n",
        "\n",
        "        # Fit and test Random Forest (multivariate)\n",
        "        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        rf_model.fit(X_train, y_train)\n",
        "\n",
        "        predictions_rf = autoregressive_predict_rf(\n",
        "            rf_model, test_df, pred_hrz=pred_hrz\n",
        "        )\n",
        "        rmse_rf = np.sqrt(mean_squared_error(ground_truth_F, predictions_rf))\n",
        "        print(f\"[RF] RMSE = {rmse_rf:.2f} F\")\n",
        "        \n",
        "        model_name = \"RandomForest\"\n",
        "        directory = f'/Users/ozanbaris/Documents/GitHub/TS-foundation-model/Aug18_ecobee_results_{noise}/{model_name}_new_ecobee_cov_{noise}_csv' \n",
        "        save_results_for_model(\n",
        "            model_name=model_name,\n",
        "            ground_truth=ground_truth_F,\n",
        "            timestamp_forecast=test_df.index[:pred_hrz],\n",
        "            forecast=predictions_rf,\n",
        "            duration=duration,\n",
        "            pred_hrz=pred_hrz,\n",
        "            mode=mode,\n",
        "            occupancy=rank,\n",
        "            batch_id=batch_id,\n",
        "            directory=directory\n",
        "        )\n",
        "\n",
        "        print(f\"Finished House {rank}\\n{'-'*40}\")\n",
        "\n",
        "        # Prepare univariate training data\n",
        "        X_train_univ = train_df[['T01_TEMP']][:-1]\n",
        "        print(f\"X_train (Univariate) shape: {X_train_univ.shape}, y_train shape: {y_train.shape}\")\n",
        "        \n",
        "        # Fit and test Ridge (univariate)\n",
        "        ridge_model_univ = Ridge()\n",
        "        ridge_model_univ.fit(X_train_univ, y_train)\n",
        "\n",
        "        predictions_ridge_univ = autoregressive_predict_ridge_univariate(\n",
        "            ridge_model_univ, test_df, pred_hrz=pred_hrz\n",
        "        )\n",
        "        rmse_ridge_univ = np.sqrt(mean_squared_error(ground_truth_F, predictions_ridge_univ))\n",
        "        print(f\"[Ridge_univ] RMSE = {rmse_ridge_univ:.2f} F\")\n",
        "        \n",
        "        model_name = \"Ridge_univ\"\n",
        "        directory = f'/Users/ozanbaris/Documents/GitHub/TS-foundation-model/Aug18_ecobee_results_{noise}/{model_name}_new_ecobee_cov_{noise}_csv' \n",
        "        save_results_for_model(\n",
        "            model_name=model_name,\n",
        "            ground_truth=ground_truth_F,\n",
        "            timestamp_forecast=test_df.index[:pred_hrz],\n",
        "            forecast=predictions_ridge_univ,\n",
        "            duration=duration,\n",
        "            pred_hrz=pred_hrz,\n",
        "            mode=mode,\n",
        "            occupancy=rank,\n",
        "            batch_id=batch_id,\n",
        "            directory=directory\n",
        "        )\n",
        "\n",
        "        # Fit and test Random Forest (univariate)\n",
        "        rf_model_univ = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        rf_model_univ.fit(X_train_univ, y_train)\n",
        "\n",
        "        predictions_rf_univ = autoregressive_predict_rf_univariate(\n",
        "            rf_model_univ, test_df, pred_hrz=pred_hrz\n",
        "        )\n",
        "        rmse_rf_univ = np.sqrt(mean_squared_error(ground_truth_F, predictions_rf_univ))\n",
        "        print(f\"[RF_univ] RMSE = {rmse_rf_univ:.2f} F\")\n",
        "\n",
        "        model_name = \"RF_univ\"\n",
        "        directory = f'/Users/ozanbaris/Documents/GitHub/TS-foundation-model/Aug18_ecobee_results_{noise}/{model_name}_new_ecobee_cov_{noise}_csv' \n",
        "        save_results_for_model(\n",
        "            model_name=model_name,\n",
        "            ground_truth=ground_truth_F,\n",
        "            timestamp_forecast=test_df.index[:pred_hrz],\n",
        "            forecast=predictions_rf_univ,\n",
        "            duration=duration,\n",
        "            pred_hrz=pred_hrz,\n",
        "            mode=mode,\n",
        "            occupancy=rank,\n",
        "            batch_id=batch_id,\n",
        "            directory=directory\n",
        "        )\n",
        "\n",
        "        print(f\"Finished House {rank}\\n{'-'*40}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-experiment",
      "metadata": {},
      "source": [
        "## Run Training Experiments Across Noise Levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-experiments",
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_id = 0 \n",
        "mode = None\n",
        "duration = 448\n",
        "pred_hrz = 64\n",
        "\n",
        "noises = [0, 0.1, 0.2, 0.5, 1, 2, 5]\n",
        "for noise in noises:\n",
        "    dataset_name = f'house_data_csvs_{noise}'\n",
        "    main_output_directory = f\"/Users/ozanbaris/Documents/GitHub/TS-foundation-model/{dataset_name}\"\n",
        "\n",
        "    all_houses_reduced = read_csvs_to_dfs(main_output_directory)\n",
        "    \n",
        "    processed_houses_reduced = {}\n",
        "    for sensor_count, houses in all_houses_reduced.items():\n",
        "        processed_houses = {}\n",
        "        for house_id, df in houses.items():\n",
        "            if 'GHI' not in df.columns:\n",
        "                print(f\"Skipping house {house_id} due to missing 'GHI' column.\")\n",
        "                continue\n",
        "            processed_houses[house_id] = process_house_data(df.copy())\n",
        "        processed_houses_reduced[sensor_count] = processed_houses\n",
        "\n",
        "    print(\"training and testing for NOISE: \", noise)\n",
        "    training_and_testing_baselines(all_houses_reduced, optimization_results_R2C2_decent, \n",
        "                                  processed_houses_reduced, pred_hrz, duration, noise, \n",
        "                                  mode, batch_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-analysis",
      "metadata": {},
      "source": [
        "## Results Analysis and Metrics Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "analysis-functions",
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_results(directory, model_name, pred_hrz, duration, valid_occupancies):\n",
        "    \"\"\"\n",
        "    Process and compute metrics for all occupancy values for a given model.\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary with metrics averaged across occupancy values\n",
        "    \"\"\"\n",
        "    all_metrics = []\n",
        "\n",
        "    for occupancy in valid_occupancies:\n",
        "        if noise == 0 and model_name not in ['R2C2', 'Ridge', 'RandomForest', 'Ridge_univ', 'RF_univ']:\n",
        "            file_path = f\"{directory}/{model_name}_new_ecobee_cov_csv/results_None_{occupancy}/{duration}_{pred_hrz}/{model_name}.csv\"\n",
        "        else:\n",
        "            file_path = f\"{directory}/{model_name}_new_ecobee_cov_{noise}_csv/results_None_{occupancy}/{duration}_{pred_hrz}/{model_name}.csv\"\n",
        "        \n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"File not found: {file_path}\")\n",
        "            continue\n",
        "\n",
        "        df = pd.read_csv(file_path)\n",
        "        ground_truth = np.array([np.array(eval(gt)) for gt in df['GroundTruth']])\n",
        "        forecast = np.array([np.array(eval(forecast)) for forecast in df['Forecast']])\n",
        "\n",
        "        metrics = compute_metrics(ground_truth, forecast)\n",
        "        all_metrics.append(metrics)\n",
        "\n",
        "    # Average metrics across all occupancy values\n",
        "    if all_metrics:\n",
        "        avg_metrics = {\n",
        "            'RMSE_all': np.mean([m['RMSE_all'] for m in all_metrics]),\n",
        "            'RMSE_1st': np.mean([m['RMSE_1st'] for m in all_metrics if m['RMSE_1st'] is not None]),\n",
        "            'RMSE_6th': np.mean([m['RMSE_6th'] for m in all_metrics if m['RMSE_6th'] is not None]),\n",
        "            'RMSE_24th': np.mean([m['RMSE_24th'] for m in all_metrics if m['RMSE_24th'] is not None])\n",
        "        }\n",
        "    else:\n",
        "        avg_metrics = None\n",
        "\n",
        "    return avg_metrics\n",
        "\n",
        "\n",
        "def analyze_noise_level(noise):\n",
        "    \"\"\"\n",
        "    Analyze results for a specific noise level.\n",
        "    \"\"\"\n",
        "    dataset_name = f'house_data_csvs_{noise}'\n",
        "    new_house_data, flattened_results, flattened_data = prepare_experiment_data(\n",
        "        dataset_name, optimization_results_R2C2_decent\n",
        "    )\n",
        "    \n",
        "    directory = f'/Users/ozanbaris/Documents/GitHub/TS-foundation-model/Aug18_ecobee_results_{noise}'\n",
        "    model_names = ['R2C2', 'Ridge', 'RandomForest', 'TimesFMCov', 'TimesFM', 'uni2ts', \n",
        "                   'uni2tsCov', 'chronos', 'LagLlama', 'moment', 'TimeGPT', 'TimeGPTCov', \n",
        "                   'RF_univ', 'Ridge_univ']\n",
        "    pred_hrz = 64\n",
        "    duration = 448\n",
        "    \n",
        "    valid_occupancies = extract_valid_occupancies(flattened_data, flattened_results, new_house_data)\n",
        "    print(f\"len of available house data {len(valid_occupancies)}\")\n",
        "\n",
        "    final_results = {}\n",
        "    for model_name in model_names:\n",
        "        print(f\"Processing model: {model_name}\")\n",
        "        avg_metrics = process_results(directory, model_name, pred_hrz, duration, valid_occupancies)\n",
        "        if avg_metrics:\n",
        "            final_results[model_name] = avg_metrics\n",
        "\n",
        "    # Save metrics summary\n",
        "    metrics_df = pd.DataFrame.from_dict(final_results, orient='index')\n",
        "    metrics_df.to_csv(f\"{directory}/metrics_summary_{noise}.csv\")\n",
        "    print(metrics_df)\n",
        "    \n",
        "    return final_results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for noise in [0, 0.1, 0.2, 0.5, 1]:\n",
        "        analyze_noise_level(noise)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-latex",
      "metadata": {},
      "source": [
        "## LaTeX Table Generation (All Models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "latex-all-models",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_overleaf_table(noise_levels, final_results_per_noise, model_names):\n",
        "    \"\"\"\n",
        "    Generates LaTeX table for all models across noise levels.\n",
        "    \"\"\"\n",
        "    table_content = \"\\\\begin{table*}[h!]\\n\"\n",
        "    table_content += \"    \\\\centering\\n\"\n",
        "    table_content += \"    \\\\caption{Results Across Different Noise Levels.}\\n\"\n",
        "    table_content += \"    \\\\label{tab:rmse}\\n\"\n",
        "    table_content += \"    \\\\resizebox{\\\\textwidth}{!}{%\\n\"\n",
        "    table_content += \"    \\\\begin{tabular}{l|\" + \"c\" * len(model_names) + \"}\\n\"\n",
        "    table_content += \"        \\\\toprule\\n\"\n",
        "    table_content += \"        \\\\textbf{Noise Level} & \\\\textbf{Metric} & \" + \" & \".join(f\"\\\\textbf{{{name}}}\" for name in model_names) + \" \\\\\\\\\\n\"\n",
        "    table_content += \"        \\\\midrule\\n\"\n",
        "\n",
        "    for noise, results in zip(noise_levels, final_results_per_noise):\n",
        "        for metric in ['RMSE_all', 'RMSE_1st', 'RMSE_6th', 'RMSE_24th']:\n",
        "            metric_values = {model: metrics.get(metric, \"-\") for model, metrics in results.items()}\n",
        "            metric_df = pd.DataFrame.from_dict(metric_values, orient='index', columns=[metric])\n",
        "            metric_df = metric_df.sort_values(metric, ascending=True)\n",
        "            best_model = metric_df.index[0]\n",
        "            second_best_model = metric_df.index[1]\n",
        "\n",
        "            if metric == 'RMSE_all':\n",
        "                row = f\"        {noise} & RMSE\\\\textsubscript{{all}}\"\n",
        "            else:\n",
        "                sub_metric = metric.split('_')[1]\n",
        "                row = f\"        & RMSE\\\\textsubscript{{{sub_metric}}}\"\n",
        "\n",
        "            for model in model_names:\n",
        "                value = metric_values.get(model, \"-\")\n",
        "                if value != \"-\":\n",
        "                    value = f\"{value:.2f}\"\n",
        "                    if model == best_model:\n",
        "                        row += f\" & \\\\textbf{{{value}}}\"\n",
        "                    elif model == second_best_model:\n",
        "                        row += f\" & \\\\underline{{{value}}}\"\n",
        "                    else:\n",
        "                        row += f\" & {value}\"\n",
        "                else:\n",
        "                    row += \" & -\"\n",
        "            row += \" \\\\\\\\\\n\"\n",
        "            table_content += row\n",
        "\n",
        "    table_content += \"        \\\\bottomrule\\n\"\n",
        "    table_content += \"    \\\\end{tabular}%\\n\"\n",
        "    table_content += \"    }\\n\"\n",
        "    table_content += \"\\\\end{table*}\\n\"\n",
        "\n",
        "    return table_content\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    noise_levels = [0, 0.1, 0.2, 0.5, 1]\n",
        "    final_results_per_noise = []\n",
        "\n",
        "    for noise in noise_levels:\n",
        "        results = analyze_noise_level(noise)\n",
        "        final_results_per_noise.append(results)\n",
        "        \n",
        "    model_names = ['R2C2', 'Ridge', 'RandomForest', 'TimesFMCov', 'uni2tsCov', 'TimeGPTCov', \n",
        "                   'TimesFM', 'uni2ts', 'TimeGPT', 'chronos', 'LagLlama', 'moment', \n",
        "                   'RF_univ', 'Ridge_univ']\n",
        "    overleaf_table = generate_overleaf_table(noise_levels, final_results_per_noise, model_names)\n",
        "    print(overleaf_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header-latex-univ",
      "metadata": {},
      "source": [
        "## LaTeX Table Generation (Univariate Models Only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "latex-univariate",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_overleaf_table_univariate(noise_levels, final_results_per_noise, model_names):\n",
        "    \"\"\"\n",
        "    Generates LaTeX table for univariate models only.\n",
        "    \"\"\"\n",
        "    table_content = \"\\\\begin{table*}[h!]\\n\"\n",
        "    table_content += \"    \\\\centering\\n\"\n",
        "    table_content += \"    \\\\caption{Univariate Model Results Across Different Noise Levels.}\\n\"\n",
        "    table_content += \"    \\\\label{tab:rmse_univ}\\n\"\n",
        "    table_content += \"    \\\\resizebox{0.6\\\\textwidth}{!}{%\\n\"\n",
        "    table_content += \"    \\\\begin{tabular}{ll|\" + \"c\" * len(model_names) + \"}\\n\"\n",
        "    table_content += \"        \\\\toprule\\n\"\n",
        "    table_content += \"        \\\\textbf{Noise} & \\\\textbf{Metric} & \" + \" & \".join(f\"\\\\textbf{{{name.replace('_', ' ')}}}\" for name in model_names) + \" \\\\\\\\\\n\"\n",
        "    table_content += \"        \\\\midrule\\n\"\n",
        "\n",
        "    for i, (noise, results) in enumerate(zip(noise_levels, final_results_per_noise)):\n",
        "        for j, metric in enumerate(['RMSE_all', 'RMSE_1st', 'RMSE_6th', 'RMSE_24th']):\n",
        "            if not results:\n",
        "                continue\n",
        "\n",
        "            metric_values = {model: metrics.get(metric, \"-\") for model, metrics in results.items()}\n",
        "            metric_df = pd.DataFrame.from_dict(metric_values, orient='index', columns=[metric])\n",
        "            \n",
        "            if not metric_df.empty:\n",
        "                metric_df = metric_df.sort_values(metric, ascending=True)\n",
        "                best_model = metric_df.index[0]\n",
        "                second_best_model = metric_df.index[1] if len(metric_df.index) > 1 else None\n",
        "            else:\n",
        "                best_model, second_best_model = None, None\n",
        "\n",
        "            noise_label = str(noise) if j == 0 else \"\"\n",
        "            metric_label = f\"RMSE\\\\textsubscript{{{metric.split('_')[1]}}}\"\n",
        "            row = f\"        {noise_label} & {metric_label}\"\n",
        "\n",
        "            for model in model_names:\n",
        "                value = metric_values.get(model, \"-\")\n",
        "                if isinstance(value, (int, float)):\n",
        "                    value_str = f\"{value:.2f}\"\n",
        "                    if model == best_model:\n",
        "                        row += f\" & \\\\textbf{{{value_str}}}\"\n",
        "                    elif model == second_best_model:\n",
        "                        row += f\" & \\\\underline{{{value_str}}}\"\n",
        "                    else:\n",
        "                        row += f\" & {value_str}\"\n",
        "                else:\n",
        "                    row += \" & -\"\n",
        "            row += \" \\\\\\\\\\n\"\n",
        "            table_content += row\n",
        "        \n",
        "        if i < len(noise_levels) - 1:\n",
        "            table_content += \" \\\\midrule\\n\"\n",
        "\n",
        "    table_content += \"        \\\\bottomrule\\n\"\n",
        "    table_content += \"    \\\\end{tabular}%\\n\"\n",
        "    table_content += \"    }\\n\"\n",
        "    table_content += \"\\\\end{table*}\\n\"\n",
        "\n",
        "    return table_content\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    noise_levels = [0, 0.1, 0.2, 0.5, 1]\n",
        "    final_results_per_noise = []\n",
        "\n",
        "    for noise in noise_levels:\n",
        "        print(f\"\\n--- Processing Noise Level: {noise} ---\")\n",
        "        dataset_name = f'house_data_csvs_{noise}'\n",
        "        new_house_data, flattened_results, flattened_data = prepare_experiment_data(\n",
        "            dataset_name, optimization_results_R2C2_decent\n",
        "        )\n",
        "        \n",
        "        directory = f'/Users/ozanbaris/Documents/GitHub/TS-foundation-model/Aug18_ecobee_results_{noise}'\n",
        "        model_names_univ = ['RF_univ', 'Ridge_univ']\n",
        "        pred_hrz = 64\n",
        "        duration = 448\n",
        "        \n",
        "        valid_occupancies = extract_valid_occupancies(flattened_data, flattened_results, new_house_data)\n",
        "        print(f\"len of available house data {len(valid_occupancies)}\")\n",
        "\n",
        "        final_results = {}\n",
        "        for model_name in model_names_univ:\n",
        "            print(f\"Processing model: {model_name}\")\n",
        "            avg_metrics = process_results(directory, model_name, pred_hrz, duration, valid_occupancies)\n",
        "            if avg_metrics:\n",
        "                final_results[model_name] = avg_metrics\n",
        "\n",
        "        final_results_per_noise.append(final_results)\n",
        "    \n",
        "    model_names_for_table = ['RF_univ', 'Ridge_univ']\n",
        "    overleaf_table = generate_overleaf_table_univariate(noise_levels, final_results_per_noise, model_names_for_table)\n",
        "    print(\"\\n--- Generated LaTeX Table ---\\n\")\n",
        "    print(overleaf_table)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
